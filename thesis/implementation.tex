\chapter{Implementation}

\section{Language}

C++11 was chosen to implement the $SRS$ data structure and the kd-tree. C++11 is a recent release of C++. C++11 combines the advantages of a modern programming language with the stability and support of a mature language which have been around for more than three decades. C++11 was chosen for several reason: It does not have garbage collection, it is a high level language with support for low level operation and contains libraries for everything needed in this project. The chrono header gives access to a high resolution clock to meassure time. The vector class of the standard template library is very straight-forward container to work with and the underlying structure is a continuous block of memory making it ideal for cache purposes. The algorithm header gives access to convenience functions for generating and sorting data. The random header gives access to random numbers through a Mersenne twister engine with uniform integer distribution. The random numbers are used to generate the input data for the two data structures, thus giving a different data set every time. The data set is generated by two lists containing the numbers $[0,n-1]$ and using the standard library's shuffle function with the Mersenne twister engine. \todo{Future work med move semantics introduceret i C++11. Future work er også parallel stuff}

\section{Design choices}

The theory describes the ball inheritance data structure as a binary tree with internal nodes and leaves. Each node has a bit vector representing the ball inheritance. In practise all the bit vectors at each level have been concatenated together to one, resulting in $\lg n$ bit vectors in all. Instead of being an actual entity, a node is just defined as which level it is from, where on that levels list its bit vector starts and how many balls its bit vector holds. Thus, a vector of bit vectors represents the ball inheritance tree. Since each ball only uses a single bit per level there would have been a lot of space wasted when nodes only held two or four balls in their bit vectors. By having a single unified bit vector per level we can pick one data type to work with independent of how many balls needs to be stored per node. The data type chosen is an unsigned fixed width integer type of $32$ bits.

We are going to describe how to support constant-time succint rank queries for a unified bit vector. First a checkpoint is added to every 32nd entry storing the amount of $1$s seen in the bit vector so far. Since the bit vectors consist of $0$s and $1$ we only need count the amount of $1$, since the amount of $0$s can be thought of as \emph{not-$1$s}. A table is computed which given a $16$ bit unsigned integer is able to answer how many $1$ are in the binary representation of the integer. The table is a flat array and supports look-up in constant time.

Given a position $i$ in the bit vector, the closest checkpoint previous to $i$ is found. The data type storing the bits in the bit vector is a $32$ bit unsigned integer. We can then only retrieve $32$ bits from the bit vector at a time\todo{ord?}. We use a \emph{binary and} to mask away the bits after $i$ and divide the $32$ integer into two $16$ bits integers. Using the precomputed table from before, we look up how many $1$s the binary represention of the two $16$ bit integer contain. \todo{EXAMPLE}. The sum of the major checkpoint and the two table look-ups is the amount of times a $1$ occurs before position $i$ in the bit vector. 

However, we are seldomly interested in knowing how many $1$s there are in a bit vector between position $0$ and $i$. We want to know how many $1$s there are between $j$ and $i$, where $j$ is the start position of a node and $i$ is an entry in that node. We know that with the ball inheritance structure that each node gives each of its children half of its balls. Thus, half of the entries in the bit vector of a node are $1$s. And thus, if $j$ is the start position of a node in the unified bit vector, there will be $\frac{j}{2}$ entries in the bit vector between $0$ and $j$ which are $1$s. Since one of the ingredients for a virtual node is the start position in the unified bit vector, we already know $j$ when looking up the rank of $i$. Using the unified bit vectors instead of an actual tree then poses no problems.


Skriv om hvordan det virker med enkelte hop. Vi har en look-up til 16 bits. Vi har en sum for hvert 32 bits. At 0 bare er komplementar af 1 når vi tæller.


\section{Ting der skal sættes ind hist og her}

In section ref-to-kd-tree the $\mathcal{O}(\sqrt{n}+k)$ running time of kd-tree search was explained to be due to a pessimistic idea that a search query would make a line through the entire region of the root. Thus, this is the worst case for a search to the kd-tree. In order to test the kd-tree and the SRS in this situation, we introduce the term \emph{slice}. A slice is a search query which extends through the entirety of the point region \todo{andet ord} in one dimension while being narrow on the other dimension. A slice which extends through the entirety of the y-dimension is called a \emph{vertical slice}. A slice which extends through the entirety of the x-dimensio is called a \emph{horizontal slice}. When describing the size of a slice, we will only specify the size of its narrow dimension, since the other is already known.

In subsection~\ref{ssection:fasterqueries} we saw how we could speed up the ball-inheritance by allowing bigger jumps by using a bigger alphabet. As introduced in subsection~\ref{sssect:succintrank} a bigger alphabet comes with a cost. Looking at the implemention of the extended alphabet and the binary packing we can set an upper bound on the storage cost of the multi-level jumps. Per level, we can define the space cost of big jumps, in bits, as:

\begin{align*}
  checkpoint_{major} &= \frac{n}{\Sigma \lg n} \cdot \Sigma \lg \frac{n}{\Sigma} \\
  checkpoint_{entry} &= n \lg (\Sigma \lg n) \\
  entry &= n \lg \Sigma
\end{align*}

When a jump reaches a leaf, the rank of the ball is not needed and thus, we can do without the two checkpoints. This way we can save a lot of space. The space has already been budgetted for, and thus we can use it to extend the size of the jumps or even add smaller jumps at other levels.\todo{Tilføj ulighed - Vis at et hop kan blive til to på samme plads eller mindre}

We have already looked at the space complexity of the both the kd-tree and the SRS, but if we look a little closer we can argue about the constants hidden away in $\mathcal{O}(n)$. \todo{noget med 32 vs 64 bits - plus at $n\lg n$ i ball inheritance ikke er $n$ words. Det er nemlig pakket og derfor bare boundet af $n$}.


\todo{Skal det her overhovedet med?} For smaller alphabets, another scheme is used. But $\sqrt{\lg n}$ is already pretty small, so instead of implementing a whole other scheme just in order to skip $1$ or $2$ levels, we just travel normally until we find a level containing jumps with a $\Sigma \geq \sqrt{\lg n}$ \todo{Eller $\Sigma \geq \lg^\epsilon n$}. This should not have a big impact. \todo{rephrase}


