\chapter{Analysis}
The purpose of this chapter is to compare the SRS data structure to the kd-tree. We are going to perform a variety of tests on the SRS data structure and the kd-tree in order to determine the run-time properties of both, mainly looking at when the SRS data structure performs better than the kd-tree.\\


In order to compare these two data structure random data will be generated and given as input to both, such that both operate on the exact same data. This random data is generated by making two lists, $X$ and $Y$ with the integers $[0,n-1]$ and shuffling them both randomly. The $n$ points given to the data structures as input are found by taking the $i$th entry of both $X$ and $Y$ and generating a point with those coordinates. This ensures that all x-coordinates are unique and all y-coordinates are unique.  When running a specific test, different data sets are generated during the test such that one tests is not only performed on a single data set. When the search query has been determined, the search will be performed different places in the data structure such that not only best-case or worst-case scenarios will occur. Finally the average of all the searches are returned as the result of the test.\\

We are going to perform two different kinds of tests, each kind in its own section. First we are going to test how a search query shaped like a square performs in both the SRS data structure and the kd-tree. \todo{lidt mere om den}. In the second test the configuration of the search query is going to one where the worst-case scenario for the kd-tree happens. It will either cover the entirety of the search area in a thin slice either in a vertical or horizontal direction. In the third section we are going to look closer at how much better the search query to the SRS data structure compares to the search query to the kd-tree when the search query is a vertical or horizontal slice and $k \leq 200$. The limit of $200$ is chosen based because it is small and a reasonable amount of results for human interaction.

The tests have been performed on data structures with data sets of size $2^m$ where $m = [17,25]$. $17$ was chosen as the smallest because it would still be big enough to show something interesting on the graphs. $25$ was chosen because the current initialization of the SRS data structure requires a bit of work and thus takes up nearly all of the main memory. Future work includes an idea for a faster and less memory requiring setup phase.


\section{Square search queries}

The kd-tree has a query time of $\mathcal{O}(\sqrt{n}+k)$. The $\sqrt{n}$ part is based on a pessimistic notion that an edge of a query will pass through the entire search area of the kd-tree. This is not always the case. We also note that when $k > \sqrt{n}$, $k$ will dominate the expression and thus the query time will increase linearly \todo{Det gør den jo alligevel}. In order to fairly compare the running time of a search query to both data structure, we are going to generate queries finding the points within an area of $\sqrt{size}\cdot\sqrt{n} \times \sqrt{size}\cdot\sqrt{n}$ where size will increase. This search query will be made with random offsets in order to query arbitrary places in the structures. So given two random numbers $x$ and $y$ a query will be $q = [x, x+\sqrt{size}\cdot\sqrt{n}] \times [y, y+\sqrt{size}\cdot\sqrt{n}]$. This kind of query will not invoke the worst-case scenario for the kd-tree and will thus give an idea of how the SRS data structure performs in contrast to the kd-tree under normal circumstances. The points generated for the data structures lie in the range of $[0,n-1] \times [0,n-1]$, which gives an area of $n^2$. If the search query has an area of $A$, each point has a $\frac{A}{n^2}$ chance of being in that search query. With $n$ points we thus expect to find $n\cdot \frac{A}{n^2}$ points in a search query with the area of $A$. In this test we set $A = \sqrt{n}\cdot\sqrt{size}\times\sqrt{n}\cdot\sqrt{size}$, where $n$ is contant to the data structure and $size$ will increase during the test. We then expect to find $n\cdot\frac{A}{n^2} = \frac{n\cdot n \cdot size}{n^2} = size$ points. This obviously depends a lot on how the points specfically are distributed in that specific case. When generating $10$ different data sets for each data structure in the tests and picking the displacements for the search query at random each search, we will expect the average amount of points returned by the search query $q = [x, x+\sqrt{size}\cdot\sqrt{n}] \times [y, y+\sqrt{size}\cdot\sqrt{n}]$ to be $size$.


As expected, the average amount of points reported from a lot of search queries with $q = [x, x + \sqrt{size}\cdot\sqrt{n}] \times [y, y + \sqrt{size}\cdot\sqrt{n}]$ were $size$.\todo{Kan jeg bare skrive det eller skal jeg vise en graf? Skal jeg skrive mere om det?}

The graphs below show the time of a search query to the SRS data structure compared to the time of a search query to the kd-tree. As described, the shape of the search query is a square. The variable $size$ increments in levels of $5$ per iteration of the test and will have a maximum of $\frac{\sqrt{n}}{2}$. The x-axis of the graphs describes the $size$ variable in the expression $A = \sqrt{n}\cdot\sqrt{size} \times \sqrt{n}\cdot\sqrt{size}$. Examining figure~\ref{fig:sqrt_17} we see that when the shape of the search query is a square, the search query to the kd-tree is always performing better than the search query to the SRS data structure. Looking closer at the figure we notice that while the search query to the SRS data structure performs worse, it is not that bad. At $size = 180$ we have window of size $\sqrt{2^{17}}\cdot\sqrt{180} \times \sqrt{2^{17}}\cdot\sqrt{180} = 4857.26 \times 4857.26$. The time to perform the search query on the SRS data structure at $size = 180$ is $15.9$ microseconds, while the search to the kd-tree takes $5.2$. This search query includes $180$ points which is $\frac{180}{131072}\cdot 100\% = 1.4\%$ of the $2^{17}$ points in the data structures. This is a relatively big query and the time to perform the search query on the SRS data structure is only a factor $3$ worse than the time of the search query on kd-tree.

Examining figure~\ref{fig:sqrt_20} with $n = 2^{20}$ the largest difference between the running time of a query to the two data structures is a factor $7$ with a query of size $\sqrt{510}\cdot\sqrt{2^{20}} \times \sqrt{510}\cdot\sqrt{2^{20}} = 23125 \times 23125$. This is a quite big window. Comparing it to the largest window size from figure~\ref{fig:sqrt_17} it is $\frac{23125^2}{4857^2} = 22.67$ times bigger, but only a factor $\frac{7}{3}$ worse.\todo{relatively}. If we look at the running times of the search query to the data structures with size $n = 2^{20}$ where the search query has the same area as we just looked at for $n = 2^{17}$, we can compare the running times of the same query to data structures of different sizes. $\sqrt{2^{17}}\cdot\sqrt{180} \times \sqrt{2^{17}}\cdot\sqrt{180} = 4857.26 \times 4857.26 = \sqrt{2^{20}}\cdot\sqrt{22.5} \times \sqrt{2^{20}}\cdot\sqrt{22.5}$. The average run time of a query with $size = 22.5$ to the SRS data structure with $n = 2^{20}$ points is $8.51$ microseconds and the average run time of a query with $size = 22.5$ to the kd-tree with $n = 2^{20}$ points is $3.69$ microseconds. This makes the search query to the SRS data structure a factor $2.31$ worse than the search query to the kd-tree. This is better than the factor $3$ found at figure~\ref{fig:sqrt_17} with a search query of the same size. However, this search window returns $180$ results at $n = 2^{17}$ and only $22.5$ at $n = 2^{20}$.

Examining figure~\ref{fig:sqrt_25} with $n = 2^{25}$ the largest search window has become quite large with a size of $\sqrt{2^{25}}\cdot\sqrt{2895} \times sqrt{2^{25}}\cdot\sqrt{2895} = 311673 \times 311673$. The biggest window now returns $2895$ points. A search query with this size to the SRS data structure and the search query to the kd-tree has a factor $\frac{386}{24} = 16.1$ difference. This a quite big difference in the search time, but it is also a big search query. \todo{mere om det}


It is obvious from the graphs that the kd-tree performs better when the search queries are square windows. But they might not be that bad . . . \todo{lidt om det}

The biggest search query at $n = 2^{17}$ is $\sqrt{180}\cdot{n} \times \sqrt{180}\cdot\sqrt{n}$. We are going lock the $size$ variable to $180$ and see how the factor between the search query to the SRS data structure and kd-tree will evolve when $n$ grows. We see this on figure~\ref{fig:factdiffsqrt180}. The graph is growing and thus the running time of a search query to the SRS data structure returning the same amount of points when $n$ is growing increases faster than the same search query to the kd-tree.\todo{Har det en forklaring - måske at den indkluderer flere?}\todo{Andre ord for at sætte en variable fast}. Examining figure~\ref{fig:factdiffsqrt100} where $size = 100$ we see that factor difference is smaller, but increases roughly the same amount from $\lg n = 17$ to $\lg n = 25$ as figure~\ref{fig:factdiffsqrt180}. 

\todo{Undersøg de forskellige grafer med en given fastsat størrelse, punkt-mængde eller prøv at divider hele grafen med antal punkter. 2'eren er nok sjovest. At undersøge 1'eren giver ikke så meget mening da $2^{25}$ og $2^{24}$ punkt-mængder da vil være mindre end $5$}



\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/sqrt_17.png}
    \caption{Square search on BIS and kd-tree. $n=2^{17}$. $\sqrt{n} = 362.04$}\label{fig:sqrt_17}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/sqrt_18.png}
    \caption{Square search on BIS and kd-tree. $n=2^{18}$. $\sqrt{n} = 512$}\label{fig:sqrt_18}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/sqrt_19.png}
    \caption{Square search on BIS and kd-tree. $n=2^{19}$. $\sqrt{n} = 724.08$}\label{fig:sqrt_19}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/sqrt_20.png}
    \caption{Square search on BIS and kd-tree. $n=2^{20}$. $\sqrt{n} = 1024$}\label{fig:sqrt_20}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/sqrt_21.png}
    \caption{Square search on BIS and kd-tree. $n=2^{21}$. $\sqrt{n} = 1448.15$}\label{fig:sqrt_21}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/sqrt_22.png}
    \caption{Square search on BIS and kd-tree. $n=2^{22}$. $\sqrt{n} = 2048$}\label{fig:sqrt_22}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/sqrt_23.png}
    \caption{Square search on BIS and kd-tree. $n=2^{23}$. $\sqrt{n} = 2896.31$}\label{fig:sqrt_23}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/sqrt_24.png}
    \caption{Square search on BIS and kd-tree. $n=2^{24}$. $\sqrt{n} = 4096$}\label{fig:sqrt_24}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/sqrt_25.png}
    \caption{Square search on BIS and kd-tree. $n=2^{25}$. $\sqrt{n} = 5792.62$}\label{fig:sqrt_25}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/factor_difference_sqrtn_180.png}
    \caption{Square search on BIS and kd-tree - factor difference with constant $size = 180$ and growing $n$}\label{fig:factdiffsqrt180}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/factor_difference_sqrtn_100.png}
    \caption{Square search on BIS and kd-tree - factor difference with constant $size = 100$ and growing $n$}\label{fig:factdiffsqrt100}
\end{figure}

\clearpage


\section{Vertical and horizontal slices}

Before introducing the graphs, we are going to look at the theoretical run-time of a search query to the kd-tree and the SRS data structure. A search query to the kd-tree has a run-time of $\mathcal{O}(\sqrt{n}+k)$ and a search query to the SRS data structure has a run-time of $\mathcal{O}(\lg n + k \cdot \lg^\epsilon n)$. When increasing the size of a slice, we expect the run-time of the two search queries to be roughly equal at $k \approx \frac{sqrt{n}}{lg^\epsilon n}$ stemming from $\sqrt{n} + k = \lg n + k \cdot \lg^\epsilon n \Leftrightarrow k = \frac{\sqrt{n} - \lg n}{\lg^\epsilon n - 1}$. The $\mathcal{O}(\lg^\epsilon n)$ describes the amount of jumps needed to perform in order to find the identity of a leaf given the identity of a ball in the ball inheritance structure. Thus, the size of $\mathcal{O}(\lg^\epsilon n)$ on how $B$ is chosen in \todo{ref} and which other meassures have been taken in order to lessen the amount of jumps. \todo{Skriv om at vi har målt dem også, og at de er sat ind på en graf - det er de værste hop vi kigger på? eller er det gennemsnittet? Hvad med grafen der viser $\frac{Skæringspunkt}{\frac{\sqrt{n}}{lg^\epsilon n}}$ - skal det være worst $\lg^\epsilon n$ eller gennemsnittet?}

Recall that the SRS data structure treats the two dimensions very differently. Given a rank space search query $\hat{q} = [\hat{x_1}, \hat{x_2}] \times [\hat{y_1}, \hat{y_2}]$, the search algorithm will find the least common ancestor of $\hat{x_1}$ and $\hat{x_2}$. From there, it will find the path to both $\hat{x_1}$ and $\hat{x_2}$ and all leaves between them will be in the range $[x_1, x_2]$. The search algorithm now has to determine which of these leaves contain a point with y-coordinate in $[y_1, y_2]$. This is done by using the ball inheritance structure from each of the fully contained nodes which were found on the path from the least common ancestor to $\hat{x_1}$ and $\hat{x_2}$.

This means that a horizontal slice and a vertical slice will be treated differently by the SRS data structure. The search query of a horizontal slice includes all x-coordinates of the search space, and thus the least common ancestor of $[\hat{x_1}, \hat{x_2}]$ will be the root of the tree. The path from the least common ancestor to $\hat{x_1}$ will only go left which means each level will give a fully contained node. The path from the least common ancestor to $\hat{x_2}$ will only go right, also yielding a fully contained node per level. The tests are to measure how big a slice can become before the kd-tree performs just as well. This means that a slice will start out being very small, $k=5$. Thus, many of the fully contained nodes will have no ball inheritance work. As the slice grows, eventually each node will have one or more balls to follow. The amount of ball inheritance each node is responsible for varies a lot, and therefore the ball inheritance will become somewhat sporadic. But the nature of the ball distribution asserts that if node has two balls or more balls for ball inheritance, these balls will be right next to each.

On the other hand we have the vertical slice. The vertical slice includes all y-coordinates of the search space, and thus the location least common ancestor of $[\hat{x_1}, \hat{x_2}]$ varies a lot dependent on the search query. But the nodes which are marked as fully contained on the path from the least common ancestor to $\hat{x_1}$ and $\hat{x_2}$ will all only contain leaves with points with y-coordinates in $[y_1, y_2]$ which means we have to do ball inheritance on all the balls belonging to fully contained nodes. Thus, the ball inheritance in vertical slices are much more batched together. Comparing a vertical and horizontal slice of the same size, the vertical slice will have good chances of being faster than the horizontal slice. With a lower LCA, the ball inheritance in the vertical slice will have to jump from a lower level than the ball inheritance in the horizontal and the balls are more batched together in the vertical. 

The first thing to be tested is how big the vertical and horizontal slices can become before the SRS data structure performs worse than the kd-tree. We are going to look at the vertical slices first. Below are some graphs showing the running time of a search query to both the SRS and the kd-tree dependent on the size of the slice. Recall from section \todo{ref} that the parameter $B$ could be set such that we could fix the size of the alphabet (and the jumps) in the ball inheritance tree. The graphs below shows results from a SRS data structure configured with $B=2$. 


\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/vert_17.png}
    \caption{vertical slice on SRS and kd-tree - data set size of $n=2^{17}$}\label{fig:vert_17}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/vert_18.png}
    \caption{vertical slice on SRS and kd-tree - data set size of $n=2^{18}$}\label{fig:vert_18}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/vert_19.png}
    \caption{vertical slice on SRS and kd-tree - data set size of $n=2^{19}$}\label{fig:vert_19}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/vert_20.png}
    \caption{vertical slice on SRS and kd-tree - data set size of $n=2^{20}$}\label{fig:vert_20}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/vert_21.png}
    \caption{vertical slice on SRS and kd-tree - data set size of $n=2^{21}$}\label{fig:vert_21}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/vert_22.png}
    \caption{vertical slice on SRS and kd-tree - data set size of $n=2^{22}$}\label{fig:vert_22}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/vert_23.png}
    \caption{vertical slice on SRS and kd-tree - data set size of $n=2^{23}$}\label{fig:vert_23}
\end{figure}

\clearpage

Across these graphs, there is a very noticable change in slope at around $k=256$ for the running time of a search query to the SRS data structure. Since $B=2$, we have a big jump at level $2^3 = 8$ which allows the ball inheritance to jump from level $8$ to a leaf in one jump. This means that the average amount of jumps per result will decrease and thus the running time will not increase as fast as before. At around $k=512$ the running-time resumes its normal behaviour. On average, the ball inheritance structure does not use the big jump at level $8$ directly anymore, resulting in a couple of steps before reaching level $8$. Since the graph shows the average run-time of different configurations of the same slice on different data sets, not all of the searches will hit level $8$ from $k>256$, but the main tedency is to. \todo{forklar tidligere - at vi snakker om main tendency, ikke hvad den er garanteret at gøre}. This tendency is described at figure~\ref{fig:jump_vert_17} and figure~\ref{fig:jump_vert_20}. We see how the graph has a local maximum at around $k=256$ and then the average amount of jumps per result decreases until $k=512$ where it starts increasing at steady level again. Figure~\ref{fig:level_vert_17} and figure~\ref{fig:level_vert_20} describes the highest level of a fully contained node. We see between $k=256$ and $k=512$ that the maximum is level $8$ and the minimum is level $7$ and that the average level increases meaning more and more fully contained node starts using level $8$. Since we $B=2$, there is a $2$-jump every $2$ levels, a $4$-jump every $4$ levels, a $8$-jump every $8$ levels and a $16$-jump every $16$ levels. This means that level $7$ the ball inheritance structure needs $3$ jumps to reach a leaf. This is why such a noticable local maximum exits on figure~\ref{fig:jump_vert_17} and figure~\ref{fig:jump_vert_20}. The jumps per results eases off because from level $8$ there is $1$ jump, from level $9$ there are $2$ jumps and from level $10$ there are $2$ jumps. Levels $11, 13, 14$ have $3$ jumps, and at level $15$ another local maximum is going to be found with $4$ jumps, just before level $16$ with $1$ jump to the leaves. However, $k=2^{16}=65,536$ is not likely to be a place where the SRS data structure performs better than the kd-tree unless we have a enormous data set \todo{regn på det}. \todo{Sæt grafer ind for større $n$}

Looking at figure~\ref{fig:level_vert_17} we see that when we reach $k=256$ the minimum highest level rises to $7$ and the maximum highest level rises to $8$. In order to write the sum of $256<k<512$ we will need to at least level $7$ because we need the two fully included nodes from level $7$ giving us $2*2^7 = 2^8 = 256$ nodes. If the least common ancestor is found at level $9$ the first fully contained node can be found at level $7$. If all the levels from level $7$ to level $1$ only have fully contained nodes, we get $k = 2*2^1 + 2*2^2 + \cdots + 2*2^7 = 508$. This is not enough to write $512$, and thus somewhere between $k=256$ and $k=512$, the search algorithm will begin using level $10$ as the least common ancestor. This is also very dependent on how the slice covers the subtrees of the least common ancestor. If the slice hits the least common ancestor right in the middle, such that the left subtree and the right subtree of the least common ancestor is of the exact same size, the level of the highest fully included node will be lower. If the slice hits the least common ancestor such there is an imbalance in the size between the left subtree and right subtree of the least common ancestor, the level of the highest fully included node will be higher, because now one subtree has to account for a bigger portion of the slice and will have to use bigger pieces. And when a subtree contains $2^8 = 256$ leaves it will have access to the jump at level $8$. The maximum level of figure~\ref{fig:level_vert_17} is explained by the fact that it is not possible to write the sum of $k<512$ using $512$ as a summand. Recall that a vertical slice conceptually only searches for the x-coordinates of the points. All the y-coordinates are already known to be included, Thus, when a node is fully included, we get all of points in its subtree.   \todo{Omformuler og sæt sammen med afsnittet fra før lige ovenover da du skriver nogenlunde det samme - bare i to forskellige tankegange}\todo{Lav en lignede figur som figur 3.2 til at forklare konceptet}


\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/jump_vert_17.png}
    \caption{Size of jumps - data set size of $n=2^{17}$. 'Average jumps' is the average of all the jumps performed normalized by the size of the slice}\label{fig:jump_vert_17}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/jump_vert_20.png}
    \caption{Size of jumps - data set size of $n=2^{20}$. 'Average jumps' is the average of all the jumps performed normalized by the size of the slice}\label{fig:jump_vert_20}
\end{figure}



\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/level_vert_17.png}
    \caption{Level of first fully contained node - data set size of $n=2^{17}$.}\label{fig:level_vert_17}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/level_vert_20.png}
    \caption{Level of first fully contained node - data set size of $n=2^{20}$.}\label{fig:level_vert_20}
\end{figure}


To summarize the graphs for vertical slices, figure~\ref{fig:vert_intersection} shows the size of the slice at the point of intersection between the running-time of a search to the SRS and the kd-tree for each $n$ tested. Recall the theory described above where it was described how the intersection point should theoretically be $k_{theoretical} = \frac{\sqrt{n} - \lg n}{\lg^\epsilon n - 1}$. Figure~\ref{fig:vert_theory} and figure~\ref{fig:vert_theory_worst_jump} show $\frac{k_{actual}}{k_{theoretical}}$. One graph uses $\lg^\epsilon n$ as the average jump per result while the other uses $\lg^\epsilon n$ as the worst case jump. If the graph is below $1$ it means that the SRS data structure performed worse than theoretically expected and if it above $1$ it means that the SRS data structure performed better than theoretically expected. The increase in the slope of the graph on figure~\ref{fig:vert_intersection} can be described by the decrease in the average jumps per results as seen on figure~\ref{fig:vert_jumps_per_lgn}. This big drop in figure~\ref{fig:vert_jumps_per_lgn} can be explained by looking at figure~\ref{fig:vert_18} and figure~\ref{fig:vert_19}. The intersection between the running time of the SRS and the kd-tree on figure~\ref{fig:vert_18} is just prior to the running time of the SRS changing its slope drastically. At figure~\ref{fig:vert_19} we see the of the running time of the SRS has changed prior to its intersection with the running time of the kd-tree. With access to the jump from level $8$, the average amount of jumps per result has been lowered. This can also be noted from figure~\ref{fig:vert_intersection} seeing that at $\lg n = 18$ the point of intersection is around $k=250$.

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/vert.png}
    \caption{Vertical slices, intersection between running time of SRS and kd-tree}\label{fig:vert_intersection}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/vert_jumps_per_lgn.png}
    \caption{Vertical slices, average jumps per result at the point of intersection between the running time of the SRS and the kd-tree}\label{fig:vert_jumps_per_lgn}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/vert_theory.png}
    \caption{Vertical slices, intersection between running time of SRS and kd-tree normalized by $k_{theoretical}$ with $\lg^\epsilon n$ being the average amount of jumps per result}\label{fig:vert_theory}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/vert_theory_worst_jump.png}
    \caption{Vertical slices, intersection between running time of SRS and kd-tree normalized by $k_{theoretical}$ with $\lg^\epsilon n$ being the worst amount of jumps per result}\label{fig:vert_theory_worst_jump}
\end{figure}


We are now going to look at the graphs for the horizontal slices. Recall that when a search query is a horizontal slice, the least common ancestor will be the root of the tree. In $[\hat{x_1}, \hat{x_2}]$, $\hat{x-1}$ will be the leftmost leaf and $\hat{x_2}$ will be the rightmost leaf. From the root to $\hat{x_1}$ and $\hat{x_2}$ there will many fully included nodes, $2$ per level to be exact, which means there will be many different nodes performing small amount of balls inheritance look-ups. Since the points are ordered by their y-coordinate in the root before distribution, and the fact that they keep this order while being distributed means that when increasing the range from $[y_1, y_2]$ to $[y_1, y_2 + 5]$ it is more likely that these $5$ new points will be found from a higher level where the range $[y_1, y_2]$ already had jumps from. It is much likely that a point is stored in a leaf which belongs to a fully included node from level $8$ with $256$ leaves than belonging to a node from level $2$ with $4$ leaves. But since the points are distributed to leaves according to their x-coordinates, it is hard to know the distribution of y-coordinates. When a search query is a horizontal slice, the position of $\hat{y_1}$ and $\hat{y_2}$ will be found on the bit vector of the root node. These position will be updated using the succint rank query while traveling from the root node to the leftmost leaf and the rightmost leaf in the tree.

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/hori_17.png}
    \caption{Horizontal slice on SRS and kd-tree - data set size of $n=2^{17}$}\label{fig:hori_17}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/hori_18.png}
    \caption{Horizontal slice on SRS and kd-tree - data set size of $n=2^{18}$}\label{fig:hori_18}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/hori_19.png}
    \caption{Horizontal slice on SRS and kd-tree - data set size of $n=2^{19}$}\label{fig:hori_19}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/hori_20.png}
    \caption{Horizontal slice on SRS and kd-tree - data set size of $n=2^{20}$}\label{fig:hori_20}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/hori_21.png}
    \caption{Horizontal slice on SRS and kd-tree - data set size of $n=2^{21}$}\label{fig:hori_21}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/hori_22.png}
    \caption{Horizontal slice on SRS and kd-tree - data set size of $n=2^{22}$}\label{fig:hori_22}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/hori_23.png}
    \caption{Horizontal slice on SRS and kd-tree - data set size of $n=2^{23}$}\label{fig:hori_23}
\end{figure}

\todo{Hvorfor knækker grafen mellem $512$ og $1024$? Hvorfor er kd-træet mærkeligt dårligt inden $k=10$? HORI}

To summarize these graphs for horizontal slices, figure~\ref{fig:hori_intersection} shows the size of the slice at the point of intersection between the running-time of a search to the SRS and kd-tree for each $n$ tested.

\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/hori.png}
    \caption{Horizontal slices, intersection between running time of SRS and kd-tree}\label{fig:hori_intersection}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/hori_jumps_per_lgn.png}
    \caption{Horizontal slices, average jumps per result at the point of intersection between the running time of the SRS and the kd-tree}\label{fig:hori_jumps_per_lgn}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/hori_theory.png}
    \caption{Horizontal slices, intersection between running time of SRS and kd-tree normalized by $k_{theoretical}$ with $\lg^\epsilon n$ being the average amount of jumps per result}\label{fig:hori_theory}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width = 0.85\textwidth]{pictures/analysis/hori_theory_worst_jump.png}
    \caption{Horizontal slices, intersection between running time of SRS and kd-tree normalized by $k_{theoretical}$ with $\lg^\epsilon n$ being the average amount of jumps per result}\label{fig:vert_theory}
\end{figure}

\section{Vertical and horizontal slices explained}



\section{Comparision of SRS and kd-tree with a constantly small $k$}

Grafer kommer
